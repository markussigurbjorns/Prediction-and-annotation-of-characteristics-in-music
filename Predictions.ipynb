{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predictions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3S8U5qXsw3Q"
      },
      "source": [
        "!pip install essentia-tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhp81Z5Asxvk"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from essentia.standard import *\n",
        "print(dir(essentia.standard))\n",
        "import pandas as pd\n",
        "import json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2IJB6xcs0w4"
      },
      "source": [
        "!wget https://essentia.upf.edu/models/classifiers/mood_acoustic/mood_acoustic-musicnn-msd-2.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_aggressive/mood_aggressive-musicnn-msd-2.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_electronic/mood_electronic-musicnn-msd-2.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_happy/mood_happy-musicnn-msd-2.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_party/mood_party-musicnn-msd-2.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_relaxed/mood_relaxed-musicnn-msd-2.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_sad/mood_sad-musicnn-msd-2.pb\n",
        "\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_acoustic/mood_acoustic-vggish-audioset-1.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_aggressive/mood_aggressive-vggish-audioset-1.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_electronic/mood_electronic-vggish-audioset-1.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_happy/mood_happy-vggish-audioset-1.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_party/mood_party-vggish-audioset-1.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_relaxed/mood_relaxed-vggish-audioset-1.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/mood_sad/mood_sad-vggish-audioset-1.pb\n",
        "\n",
        "!wget https://essentia.upf.edu/models/classifiers/danceability/danceability-musicnn-msd-2.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/gender/gender-musicnn-msd-2.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/tonal_atonal/tonal_atonal-musicnn-msd-2.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/voice_instrumental/voice_instrumental-musicnn-msd-2.pb\n",
        "\n",
        "!wget https://essentia.upf.edu/models/classifiers/danceability/danceability-vggish-audioset-1.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/gender/gender-vggish-audioset-1.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/tonal_atonal/tonal_atonal-vggish-audioset-1.pb\n",
        "!wget https://essentia.upf.edu/models/classifiers/voice_instrumental/voice_instrumental-vggish-audioset-1.pb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFVIgT3ns3iq"
      },
      "source": [
        "models_musicnn = [\n",
        "                 '/content/danceability-musicnn-msd-2.pb',\n",
        "                 '/content/gender-musicnn-msd-2.pb',\n",
        "                 '/content/mood_acoustic-musicnn-msd-2.pb',\n",
        "                 '/content/mood_aggressive-musicnn-msd-2.pb',\n",
        "                 '/content/mood_electronic-musicnn-msd-2.pb',\n",
        "                 '/content/mood_happy-musicnn-msd-2.pb',\n",
        "                 '/content/mood_party-musicnn-msd-2.pb',\n",
        "                 '/content/mood_relaxed-musicnn-msd-2.pb',\n",
        "                 '/content/mood_sad-musicnn-msd-2.pb',\n",
        "                 '/content/tonal_atonal-musicnn-msd-2.pb',\n",
        "                 '/content/voice_instrumental-musicnn-msd-2.pb'              \n",
        "]\n",
        "\n",
        "models_vgg = [\n",
        "              '/content/danceability-vggish-audioset-1.pb',\n",
        "              '/content/gender-vggish-audioset-1.pb',\n",
        "              '/content/mood_acoustic-vggish-audioset-1.pb',\n",
        "              '/content/mood_aggressive-vggish-audioset-1.pb',\n",
        "              '/content/mood_electronic-vggish-audioset-1.pb',\n",
        "              '/content/mood_happy-vggish-audioset-1.pb',\n",
        "              '/content/mood_party-vggish-audioset-1.pb',\n",
        "              '/content/mood_relaxed-vggish-audioset-1.pb',\n",
        "              '/content/mood_sad-vggish-audioset-1.pb',\n",
        "              '/content/tonal_atonal-vggish-audioset-1.pb',\n",
        "              '/content/voice_instrumental-vggish-audioset-1.pb'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNNxqcAGtDkS"
      },
      "source": [
        "To run the code set your folders where the comments are\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qSD04Jzs6TF"
      },
      "source": [
        "data_directory = '/content/drive/MyDrive/ampresults/' #folder for prediction data for musicnn\n",
        "i = 0;\n",
        "for root, dirs, files in os.walk('/content/drive/MyDrive/mtg-jamendo-annotator/static/tracks'): #folder where all your tracks are\n",
        "  for file in files:\n",
        "    if file.endswith('.mp3'):\n",
        "      i+=1\n",
        "      print(i)\n",
        "      print(file)\n",
        "      predictions = dict()\n",
        "      for model in models_musicnn:\n",
        "        tf_model = TensorflowPredictMusiCNN(graphFilename=model)\n",
        "        song = os.path.abspath(os.path.join(root, file))\n",
        "        audio = EasyLoader(filename=song, sampleRate=16000, endTime=180)()\n",
        "        prediction = tf_model(audio)\n",
        "        prediction = np.mean(prediction, axis=0)\n",
        "        predictions[model[9:].split('-')[0]] = int(np.argmax(prediction))\n",
        "      json_file = data_directory+file+'.json';\n",
        "      with open(json_file, 'w') as f:\n",
        "        json.dump(predictions, f)\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf8s0wDAs-_h"
      },
      "source": [
        "data_directory = '/content/drive/MyDrive/ampresultsVGG/'. #folder for prediction data for VGG\n",
        "i = 0;\n",
        "for root, dirs, files in os.walk('/content/drive/MyDrive/mtg-jamendo-annotator/static/tracks'):  #folder where all your tracks are\n",
        "  for file in files:\n",
        "    if file.endswith('.mp3'):\n",
        "      i+=1\n",
        "      print(i)\n",
        "      print(file)\n",
        "      predictions = dict()\n",
        "      for model in models_vgg:\n",
        "        tf_model = TensorflowPredictVGGish(graphFilename=model)\n",
        "        song = os.path.abspath(os.path.join(root, file))\n",
        "        audio = EasyLoader(filename=song, sampleRate=16000, endTime=180)()\n",
        "        prediction = tf_model(audio)\n",
        "        prediction = np.mean(prediction, axis=0)\n",
        "        predictions[model[9:].split('-')[0]] = int(np.argmax(prediction))\n",
        "      json_file = data_directory+file+'.json';\n",
        "      with open(json_file, 'w') as f:\n",
        "        json.dump(predictions, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}